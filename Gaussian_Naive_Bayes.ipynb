{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Naive Bayes to the Training set\n",
    "\n",
    "posterior = prior occurrances * liklihood / evidence\n",
    "The \"gaussian\" and \"naive\" come from two assumptions present in this likelihood:\n",
    "1. we assume each feature is uncorrelated from each other. That is, meannfreq is                  independent of sd or median etc.. This is obviously not true, and is a \"naive\"                assumption.\n",
    "2. we assume have that the value of the features (e.g. meannfreq of women) are normally          (gaussian) distributed. This means that p(meannfreqâˆ£female) is calculated by inputing          the required parameters into the probability density function of the normal                    distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r train_x\n",
    "%store -r test_x\n",
    "%store -r train_y\n",
    "%store -r test_y\n",
    "%store -r genderLabels\n",
    "\n",
    "%store -r train_x_two_features\n",
    "%store -r test_x_two_features\n",
    "%store -r train_y_two_features\n",
    "%store -r test_y_two_features\n",
    "\n",
    "%store -r transformed_train_x\n",
    "%store -r transformed_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-09b931dfce58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'male'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtemp_train_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label_map = {\n",
    "    0: 'female',\n",
    "    1: 'male'\n",
    "}\n",
    "temp_train_y.map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ..., \n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_train_y = train_y.reshape(len(train_y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# female -> 0\n",
    "# male -> 1\n",
    "# Translate every element in numpy array according to key\n",
    "my_dict = {0:\"female\",1:\"male\"}\n",
    "temp_train_y = np.vectorize(my_dict.get)(train_y)\n",
    "# Reshape train_y\n",
    "temp_train_y = temp_train_y.reshape(len(temp_train_y), 1)\n",
    "# Join two arrays vertically\n",
    "train_df = np.concatenate((train_x, temp_train_y), axis=1)\n",
    "# Columns\n",
    "columns_new = [\"meanfreq\",\"sd\",\"median\",\"Q25\",\"Q75\",\"IQR\",\"skew\",\"kurt\",\"sp.ent\",\"sfm\",\"mode\",\"centroid\",\"meanfun\",\"minfun\",\"maxfun\",\"meandom\",\"mindom\",\"maxdom\",\"dfrange\",\"modindx\",\"label\"]\n",
    "# Pass in array and columns\n",
    "train_df =pd.DataFrame(train_df, columns=columns_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For both the classes 0 and 1, and for each of the 20 features, we have thus saved the mean and the standard in summary. \n",
    "# For example, for the class 0 (female), and feature 1 (ie, sd), mean and the standard for this attribute are 0.060910268026077803 and 0.00034668419803097784\n",
    "\n",
    "def getSummary(data,n_cls):\n",
    "    data_means = data.groupby('label').mean()\n",
    "    data_variance = data.groupby('label').var()\n",
    "    \n",
    "    cnames = np.array(data.columns.tolist())[:-1] \n",
    "    classes = np.unique(labels)\n",
    "    classnames = np.array(['female','male'])\n",
    "    summary = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        #initializing the dictionary\n",
    "        summary[cls] = defaultdict(list)\n",
    "    for cls in classes:\n",
    "        for j in range(0, n_cls):\n",
    "            print(classnames[cls])\n",
    "            summary[cls][j] += list(np.array([data_means[cnames[j]][data_means.index == classnames[cls]].values[0],\n",
    "                                          data_variance[cnames[j]][data_variance.index == classnames[cls]].values[0]]))\n",
    "            \n",
    "    print summary   \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-654e906e5507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-c4853e834ebc>\u001b[0m in \u001b[0;36mgetSummary\u001b[0;34m(data, n_cls)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_groupby_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'numeric_only'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only)\u001b[0m\n\u001b[1;32m   3352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3353\u001b[0m         new_items, new_blocks = self._cython_agg_blocks(\n\u001b[0;32m-> 3354\u001b[0;31m             how, alt=alt, numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   3355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[0;34m(self, how, alt, numeric_only)\u001b[0m\n\u001b[1;32m   3423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3425\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No numeric types to aggregate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3427\u001b[0m         \u001b[0;31m# reset the locs in the blocks to correspond to our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "summary = getSummary(train_df,train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.314653</td>\n",
       "      <td>-0.455157</td>\n",
       "      <td>0.261732</td>\n",
       "      <td>0.484678</td>\n",
       "      <td>-0.070203</td>\n",
       "      <td>-0.590939</td>\n",
       "      <td>-0.031266</td>\n",
       "      <td>-0.084121</td>\n",
       "      <td>-0.471300</td>\n",
       "      <td>-0.337293</td>\n",
       "      <td>0.158686</td>\n",
       "      <td>0.314653</td>\n",
       "      <td>0.811053</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>0.166368</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>0.183518</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>-0.021680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.330399</td>\n",
       "      <td>0.477935</td>\n",
       "      <td>-0.274830</td>\n",
       "      <td>-0.508933</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>0.620511</td>\n",
       "      <td>0.032830</td>\n",
       "      <td>0.088331</td>\n",
       "      <td>0.494885</td>\n",
       "      <td>0.354173</td>\n",
       "      <td>-0.166627</td>\n",
       "      <td>-0.330399</td>\n",
       "      <td>-0.851641</td>\n",
       "      <td>-0.124090</td>\n",
       "      <td>-0.174694</td>\n",
       "      <td>-0.199296</td>\n",
       "      <td>-0.192702</td>\n",
       "      <td>-0.198474</td>\n",
       "      <td>-0.195104</td>\n",
       "      <td>0.022765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "label                                                                         \n",
       "0.0    0.314653 -0.455157  0.261732  0.484678 -0.070203 -0.590939 -0.031266   \n",
       "1.0   -0.330399  0.477935 -0.274830 -0.508933  0.073716  0.620511  0.032830   \n",
       "\n",
       "           kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "label                                                                         \n",
       "0.0   -0.084121 -0.471300 -0.337293  0.158686  0.314653  0.811053  0.118176   \n",
       "1.0    0.088331  0.494885  0.354173 -0.166627 -0.330399 -0.851641 -0.124090   \n",
       "\n",
       "         maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "label                                                              \n",
       "0.0    0.166368  0.189798  0.183518  0.189015  0.185805 -0.021680  \n",
       "1.0   -0.174694 -0.199296 -0.192702 -0.198474 -0.195104  0.022765  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the means of each feature\n",
    "data_means = train_x_df.groupby('label').mean()\n",
    "# View the values\n",
    "data_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.020998</td>\n",
       "      <td>1.223149</td>\n",
       "      <td>0.798805</td>\n",
       "      <td>1.056744</td>\n",
       "      <td>0.973134</td>\n",
       "      <td>1.020283</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.552644</td>\n",
       "      <td>1.102338</td>\n",
       "      <td>1.040779</td>\n",
       "      <td>0.772381</td>\n",
       "      <td>1.020998</td>\n",
       "      <td>0.330011</td>\n",
       "      <td>1.295627</td>\n",
       "      <td>0.523229</td>\n",
       "      <td>1.200111</td>\n",
       "      <td>1.299962</td>\n",
       "      <td>1.202630</td>\n",
       "      <td>1.204760</td>\n",
       "      <td>0.835003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.766369</td>\n",
       "      <td>0.321059</td>\n",
       "      <td>1.065409</td>\n",
       "      <td>0.436022</td>\n",
       "      <td>1.019320</td>\n",
       "      <td>0.228061</td>\n",
       "      <td>1.468564</td>\n",
       "      <td>1.456243</td>\n",
       "      <td>0.415699</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>1.186494</td>\n",
       "      <td>0.766369</td>\n",
       "      <td>0.288032</td>\n",
       "      <td>0.661205</td>\n",
       "      <td>1.442745</td>\n",
       "      <td>0.713981</td>\n",
       "      <td>0.614181</td>\n",
       "      <td>0.711975</td>\n",
       "      <td>0.712331</td>\n",
       "      <td>1.173976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "label                                                                         \n",
       "0.0    1.020998  1.223149  0.798805  1.056744  0.973134  1.020283  0.553424   \n",
       "1.0    0.766369  0.321059  1.065409  0.436022  1.019320  0.228061  1.468564   \n",
       "\n",
       "           kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "label                                                                         \n",
       "0.0    0.552644  1.102338  1.040779  0.772381  1.020998  0.330011  1.295627   \n",
       "1.0    1.456243  0.415699  0.713796  1.186494  0.766369  0.288032  0.661205   \n",
       "\n",
       "         maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "label                                                              \n",
       "0.0    0.523229  1.200111  1.299962  1.202630  1.204760  0.835003  \n",
       "1.0    1.442745  0.713981  0.614181  0.711975  0.712331  1.173976  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the variance of each feature\n",
    "data_variance = train_x_df.groupby('label').var()\n",
    "# View the values\n",
    "data_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate the probability density of each of the terms of the likelihood \n",
    "# We use mean and standard deviation of input values (x) for each class to summarize the distribution\n",
    "# Probabilities of new x values are calculated using the Gaussian Probability Density Function (PDF).\n",
    "\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "    # Input the arguments into a probability density function\n",
    "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
    "    return p\n",
    "\n",
    "# We calculate the probability that the value of the random variable will be between x - 0.01 and x + 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19947114020071635"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "p_x_given_y(2, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    # p(x|y) (e.g. p(meannfreqâˆ£female))\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.iteritems():\n",
    "        if (classValue == 0):\n",
    "            probabilities[classValue] = P_female\n",
    "        \n",
    "        else:\n",
    "            probabilities[classValue] = P_male\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, var = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= p_x_given_y(x, mean, var)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculateClassProbabilities(summary, test_x[10])\n",
    "# PDF can be greater than 1, but it can't be greater than 1 for a large interval\n",
    "# because of the non-negativity and integral constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a Prediction\n",
    "import operator\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    #print probabilities\n",
    "    probabilities = sorted(probabilities.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return probabilities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_x[10])\n",
    "print('Our prediction for test_x[10] is %s'  % (predict(summary, test_x[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def GaussianNB_Classifier(test_x,test_y):\n",
    "    results = []\n",
    "    for i in range(len(test_x)):\n",
    "        test_single = test_x[i]\n",
    "        res = predict(summary, test_single)\n",
    "        results.append(res)\n",
    "    # We evaluate the accuracy of the model by calculating a ratio of the total correct predictions out of all predictions made (the classification accuracy)\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for j in range(len(test_y)):\n",
    "        if(results[j] == test_y[j]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    " \n",
    "    print('Correct rate is %s'  % (float(correct)/(correct+wrong)))\n",
    "    print(classification_report(test_y,results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Use classification reports to evaluate how well Gaussian Naive Bayes performed with all features \\n\")\n",
    "print(\"in-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"out-of-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are wondering if there is a big difference in the results \n",
    "# when used Sklearn package vs. our own algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_x, train_y)\n",
    "prediction = nb.predict(test_x)\n",
    "\n",
    "print('NB result: ', accuracy_score(test_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Is it enough of these two features to make predictions? \n",
    "## Random Forest with 2 features ('meanfun', 'IQR')\n",
    "\n",
    "voice_new_data = voice_data[['IQR','meanfun','label']]\n",
    "train_new_x = train_x[:,[5,12]]\n",
    "test_new_x = test_x[:,[5,12]]\n",
    "summary = getSummary(voice_new_data, train_new_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Use classification reports to evaluate how well Gaussian Naive Bayes performed with only 2 features \\n\")\n",
    "print(\"In-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(train_new_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Out-of-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(test_new_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We did observe some improvement in performance when we implement Gaussian Naive Bayes with 2 features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
