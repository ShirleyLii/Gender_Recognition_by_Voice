{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Naive Bayes to the Training set\n",
    "\n",
    "posterior = prior occurrances * liklihood / evidence\n",
    "The \"gaussian\" and \"naive\" come from two assumptions present in this likelihood:\n",
    "1. we assume each feature is uncorrelated from each other. That is, meannfreq is                  independent of sd or median etc.. This is obviously not true, and is a \"naive\"                assumption.\n",
    "2. we assume have that the value of the features (e.g. meannfreq of women) are normally          (gaussian) distributed. This means that p(meannfreq∣female) is calculated by inputing          the required parameters into the probability density function of the normal                    distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For both the classes 0 and 1, and for each of the 20 features, we have thus saved the mean and the standard in summary. \n",
    "# For example, for the class 0 (female), and feature 1 (ie, sd), mean and the standard for this attribute are 0.060910268026077803 and 0.00034668419803097784\n",
    "\n",
    "def getSummary(data,n_cls):\n",
    "    data_means = data.groupby('label').mean()\n",
    "    data_variance = data.groupby('label').var()\n",
    "    \n",
    "    cnames = np.array(data.columns.tolist())[:-1] \n",
    "    classes = np.unique(labels)\n",
    "    classnames = np.array(['female','male'])\n",
    "    summary = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        #initializing the dictionary\n",
    "        summary[cls] = defaultdict(list)\n",
    "    for cls in classes:\n",
    "        for j in range(0, n_cls):\n",
    "            summary[cls][j] += list(np.array([data_means[cnames[j]][data_means.index == classnames[cls]].values[0],\n",
    "                                          data_variance[cnames[j]][data_variance.index == classnames[cls]].values[0]]))\n",
    "            \n",
    "    print summary   \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate the probability density of each of the terms of the likelihood \n",
    "# We use mean and standard deviation of input values (x) for each class to summarize the distribution\n",
    "# Probabilities of new x values are calculated using the Gaussian Probability Density Function (PDF).\n",
    "\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "    # Input the arguments into a probability density function\n",
    "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
    "    return p\n",
    "\n",
    "# We calculate the probability that the value of the random variable will be between x - 0.01 and x + 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19947114020071635"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_given_y(2, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    # p(x|y) (e.g. p(meannfreq∣female))\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.iteritems():\n",
    "        if (classValue == 0):\n",
    "            probabilities[classValue] = P_female\n",
    "        \n",
    "        else:\n",
    "            probabilities[classValue] = P_male\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, var = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= p_x_given_y(x, mean, var)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: defaultdict(<type 'list'>, {0: [0.1820944896115172, 0.0012308752581067402], 1: [0.060910268026077803, 0.00034668419803097784], 2: [0.1917280262312383, 0.0017774599742267337], 3: [0.14702387059375047, 0.0036290919666673088], 4: [0.22548547752547576, 0.00063632875476289966], 5: [0.078461606931725311, 0.0022900586608465912], 6: [4.0640588447321946, 19.981937462664831], 7: [54.002626990024538, 19590.277614486084], 8: [0.90142862788307576, 0.0012700827341601848], 9: [0.41288555139182237, 0.034561907670857914], 10: [0.14347753932340088, 0.0095338163743767454], 11: [0.1820944896115172, 0.0012308752581067402], 12: [0.18174512313129237, 0.0010533924062263776], 13: [0.057006064004829819, 0.0029821249604632294], 14: [0.25470451949136141, 0.00048094458979231494], 15: [0.38878526219443821, 0.061783853630318339], 16: [0.079211956521739124, 0.031561318696823978], 17: [1.0041100543478261, 0.4979468848824341], 18: [0.92489809782608701, 0.47287455352904884], 19: [0.27612166784533365, 0.010880811969970046]}), 1: defaultdict(<type 'list'>, {0: [0.15952343148055828, 0.00092792787946708796], 1: [0.069073023922865198, 0.00015391193557457342], 2: [0.15851299019275286, 0.0016227355494716825], 3: [0.10589087223956763, 0.0018891923300362763], 4: [0.21718981948124469, 0.00080334242008025744], 5: [0.11129894724167697, 0.00097563249694219696], 6: [4.2635011852042881, 30.680457382288921], 7: [68.912399943402889, 31771.580084937101], 8: [0.92624319057583548, 0.0009679151782860055], 9: [0.52290533911088877, 0.031901675620162266], 10: [0.10796219935075754, 0.0075837667195991871], 11: [0.15952343148055828, 0.00092792787946708796], 12: [0.11848462931089836, 0.00070117392280324466], 13: [0.039022021646669333, 0.0012232667392980351], 14: [0.20977296735562273, 0.0030376212804991746], 15: [0.32862641050084274, 0.047032342277975724], 16: [0.047010869565217391, 0.0059089308652340074], 17: [1.0820991847826087, 0.80480983220627922], 18: [1.0350883152173913, 0.79256655300322132], 19: [0.29344750256419699, 0.012727836276226149]})}\n"
     ]
    }
   ],
   "source": [
    "summary = getSummary(voice_data,train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 102278236.1080021, 1: 107544.30612546373}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateClassProbabilities(summary, test_x[10])\n",
    "# PDF can be greater than 1, but it can't be greater than 1 for a large interval\n",
    "# because of the non-negativity and integral constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a Prediction\n",
    "import operator\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    #print probabilities\n",
    "    probabilities = sorted(probabilities.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return probabilities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.182440531475707 0.0826908723499453 0.21594095940959399 0.144132841328413\n",
      " 0.23686346863468602 0.092730627306273 2.50602933066259 10.818060222584501\n",
      " 0.9211971774786719 0.531724451397257 0.22859778597785999 0.182440531475707\n",
      " 0.205320023468065 0.0869565217391304 0.25 0.262152777777778 0.0234375\n",
      " 0.45703125 0.43359375 0.29214929214929203]\n",
      "Our prediction for test_x[10] is 0\n"
     ]
    }
   ],
   "source": [
    "print(test_x[10])\n",
    "print('Our prediction for test_x[10] is %s'  % (predict(summary, test_x[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def GaussianNB_Classifier(test_x,test_y):\n",
    "    results = []\n",
    "    for i in range(len(test_x)):\n",
    "        test_single = test_x[i]\n",
    "        res = predict(summary, test_single)\n",
    "        results.append(res)\n",
    "    # We evaluate the accuracy of the model by calculating a ratio of the total correct predictions out of all predictions made (the classification accuracy)\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for j in range(len(test_y)):\n",
    "        if(results[j] == test_y[j]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    " \n",
    "    print('Correct rate is %s'  % (float(correct)/(correct+wrong)))\n",
    "    print(classification_report(test_y,results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use classification reports to evaluate how well Gaussian Naive Bayes performed with all features \n",
      "\n",
      "in-sample accuracy in Gaussian Naive Bayes:\n",
      "Correct rate is 0.807065217391\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.76      0.80       184\n",
      "          1       0.78      0.85      0.82       184\n",
      "\n",
      "avg / total       0.81      0.81      0.81       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Use classification reports to evaluate how well Gaussian Naive Bayes performed with all features \\n\")\n",
    "print(\"in-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out-of-sample accuracy in Gaussian Naive Bayes:\n",
      "Correct rate is 0.782608695652\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78        46\n",
      "          1       0.77      0.80      0.79        46\n",
      "\n",
      "avg / total       0.78      0.78      0.78        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"out-of-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NB result: ', 0.78260869565217395)\n"
     ]
    }
   ],
   "source": [
    "# We are wondering if there is a big difference in the results \n",
    "# when used Sklearn package vs. our own algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(train_x, train_y)\n",
    "prediction = nb.predict(test_x)\n",
    "\n",
    "print('NB result: ', accuracy_score(test_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: defaultdict(<type 'list'>, {0: [0.078461606931725311, 0.0022900586608465912], 1: [0.18174512313129237, 0.0010533924062263776]}), 1: defaultdict(<type 'list'>, {0: [0.11129894724167697, 0.00097563249694219696], 1: [0.11848462931089836, 0.00070117392280324466]})}\n"
     ]
    }
   ],
   "source": [
    "# Is it enough of these two features to make predictions? \n",
    "## Random Forest with 2 features ('meanfun', 'IQR')\n",
    "\n",
    "voice_new_data = voice_data[['IQR','meanfun','label']]\n",
    "train_new_x = train_x[:,[5,12]]\n",
    "test_new_x = test_x[:,[5,12]]\n",
    "summary = getSummary(voice_new_data, train_new_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use classification reports to evaluate how well Gaussian Naive Bayes performed with only 2 features \n",
      "\n",
      "In-sample accuracy in Gaussian Naive Bayes:\n",
      "Correct rate is 0.883152173913\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.88      0.88       184\n",
      "          1       0.88      0.89      0.88       184\n",
      "\n",
      "avg / total       0.88      0.88      0.88       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Use classification reports to evaluate how well Gaussian Naive Bayes performed with only 2 features \\n\")\n",
    "print(\"In-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(train_new_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample accuracy in Gaussian Naive Bayes:\n",
      "Correct rate is 0.869565217391\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.83      0.86        46\n",
      "          1       0.84      0.91      0.87        46\n",
      "\n",
      "avg / total       0.87      0.87      0.87        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Out-of-sample accuracy in Gaussian Naive Bayes:\")\n",
    "GaussianNB_Classifier(test_new_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We did observe some improvement in performance when we implement Gaussian Naive Bayes with 2 features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
